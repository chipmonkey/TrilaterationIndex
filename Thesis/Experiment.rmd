---
title: "Experiment"
author: "Chip Lynch"
date: "3/13/2021"
output:
  pdf_document: default
  html_document: default
---

# Experimentation

## Experimental Setup

We plan experiments for Network Adequacy in SQL databases, and Nearest Neighbor applications using Python.

### Experiment 1: Python Nearest Neighbors with ANN

1. We adapt the popular Python package scikit-learn to execute our Trilateration Index and perform nearest-neighbor search.
2. We adapt the ann-benchmarks software, which is designed explicitly for comparing performance of nearest neighbor algorithms[@Amueller2020], to record results.  This includes the addition of a geodesic dataset and distance function (ann-benchmarks only supported jaccard, hamming, euclidean, and angular distance functions) for consistency (see [Geodesic query points] for details).
3. We implement the four algorithms described in [Multilateration NN Algorithms], namely "Trilateration" (TRI), "TrilaterationApprox" (TIA), "TrilaterationExpand" (TIE), and "TrilaterationExpand2" (TIE2)
4. We execute the ann-benchmarks software against our and other modern $NN$ algorithms, and record the results in [ANN Benchmarks]

Note that we use a widely available geodesic distance implementation from Geopy to provide a consistent distance function implementation, thus avoiding any bias in results due to differences between implementations.[@geopy]  Since the geodesic distance function is the result of a convergent series, it is possible to vary the precision of the calculation, trading performance for accuracy.  We use the default settings in the Geopy implementation, again for a consistent comparison across $NN$ techniques.  

### Experiment 2: SQL Network Adequacy

For Network Adequacy, no standard benchmark exists (such as ann-benchmarks for Nearest Neighbor), so our experimental setup requires a bit more setup.  We use the following steps:

1. We take the same 150,000 point geospatial data set used in the $NN$ experiment (see [Geodesic query points] for details) and assign the points randomly to 15 categories of varying sizes (see table [Record Counts by Category ID]).

```{r categories, echo=FALSE}
library(knitr)
cats <- read.csv('../data/lat_long_categorized.csv')
cats[cats$Category < 10,'Category'] <- '0-9'
cats$Category <- as.factor(cats$Category)
results <- t(table(cats$Category))
results[1] <- results[1] / 10
row.names(results) <- c('Record Count')
kable(results, caption="Record Counts by Category ID")
```

2. We implement our two Network Algorithms (NAIVE-NA and TRILAT-NA) described in [Multilateration NA Algorithms] in the SQL database.
3. We execute these over various combinations of categories in our dataset, logging the duration of each combination for comparison.

\newpage

## Experimental Results

```{r child = 'ANN_Benchmarks.rmd'}
```

\newpage

```{r child = 'SQL_Results.rmd'}