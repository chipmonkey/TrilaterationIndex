---
title: "Math Theory"
author: "Chip Lynch"
date: "1/31/2021"
output: pdf_document
---


## Underlying Mathematical Concepts

The benefit of storing geographic points as a set of trilateration distances rather than latitude and longitude boils down to the simplification of comparing distances between points by shortcutting complex distance queries using simple subtractions.  We discuss the math behind the geospatial queries, to exhibit their complexity, and set some theoretical bounds on quick distance calculations using the trilateration index.


### High Cost of Geospatial Calculations

Calculating the distance between two points around the globe with precision is required for Satellite Communications and Geospatial Positioning Systems (GPS), as well as for ground based surveying and generally all applications requiring precise (sub-meter) measurements accounting for the curvature of the earth.[@ASPRS2015]

#### Haversine
One of the simplest distance calculations between two points on the earth's surface -- namely the Haversine Formula [@gade2010], which dates to the early 1800s-- works by assuming the earth is a sphere.  The calculation for the distance between two points on the earth, using this formula goes as:

Given the radius of a spherical representation of the earth as $r = 6356.752 km$ and the coordinates of two points (latitude, longitude) given by $(\phi_1, \lambda_1)$ and $(\phi_2, \lambda_2)$, the distance $d$ between those points along the surface of the earth is:

$$d = 2r\sin^{-1}(\sqrt{\sin^2(\frac{\phi_2-\phi_1}{2}) +\cos(\phi_1)\cos(\phi_2)\sin^2(\frac{\lambda_2-\lambda_1}{2})})$$

Obviously this is somewhat computationally complex, comprising five trigonometric functions, two subtractions and a square root.  While it is a closed form solution, it causes an error over long distances of up to 0.3%, which can mean distances are off by up to 3 meters over distances of 1000 kilometers.  From the equator to the north pole, which on a sphere is defined as precisely 10,000 km, the actual distance is off by over 2 km, which is a sizeable error for even the most robust applications.


#### Vincenty and Karney's Improvements (Geodesics)

The shortcomings of the spherical calculation was thoroughly discussed by Walter Lambert in 1942.[@Lambert1942]  However it wasn't until 1975 that an iterative computational approach came about to give more accurate distance measurements with a model of the earth more consistent with reality.  By considering the earth as an ellipsoid, rather than a sphere, the distance calculations are more complex, but far more precise.  Vincenty was able to create an iterative approach accurate down to the millimeter level on an ideal elliptical earth; far more accurate than the Haversine calculations[@Vincenty1975].  This algorithm, however, was a series which failed to converge for points at near opposite sides of the earth.  Karney was able to improve upon this in 2013 to fix these antipodal non-convergences, and the resulting formulae are now widely available in geospatial software libraries where precision is required (commonly referred to as "Geodesic" distances. [@Karney2013]

To get an idea of the relative complexity, we ran some basic timings using widely available python libraries that perform both calculations.  The Haversine is about 22 times faster than Karney's iterative approach.  For comparison, we include Euclidean functions, which are of course computationally simple, although their usefulness on curved surfaces are minimal:

```{r geodist_timings, echo=FALSE, results ='asis'}
library(knitr)
times <- data.frame(title=c("Geodesic", "Haversine", "Euclidean"),
                    time=c(1.211069, 0.0553729, 0.0021042),
                    ratio=c(1.211069/0.0021042, 0.0553729/0.0021042, 0.0021042/0.0021042))
kable(times, caption="Timings (seconds) of 5000 Calls to Distance Functions")
```


## Simple distance functions

Before jumping into [Network Adequacy] and [Nearest Neighbor] algorithms let's look at the core usage of the trilateration data structure and its use in simple distance functions.

What we mean by 'simple distance functions' is one of the following primitive functions common to SQL or map related software libraries:

* $D(p, q)$: returns the distance between points p and q
* $Within(d, q, P)$:  returns the set of all points in $P$ within distance $d$ of query point $q$
* $AnyWithin(d, q, P)$: returns a boolean result - True if $Within(d, q, P)$ is non-empty; False otherwise

### Distance Function

How can we use the Trilateration Index ($TI$) to improve the performance of a single distance function $D(p, q)$?  In the simplest case, we cannot... the construction of the $TI$ structures requires three distance functions to be calculated each for $p$ and $q$ (to the three fixed reference points).

However, for large datasets with fixed points where many distances need to be calculated between them, particularly if the distance function itself is computationally intensive (such as geospatial distances on an accurate ellipsoid model of earth) [@Lambert1942], we can use the $TI$ structure to create approximate distances, and provide upper and lower bounds on exact values.

For example, let's take our sample data:

```{r sampleDistance, fig.align="center", echo=FALSE}
```
